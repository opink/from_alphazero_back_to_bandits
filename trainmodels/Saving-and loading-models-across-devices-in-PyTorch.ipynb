{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\cliptest\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Saving and loading models across devices in PyTorch\n",
    "===================================================\n",
    "\n",
    "There may be instances where you want to save and load your neural\n",
    "networks across different devices.\n",
    "\n",
    "Introduction\n",
    "------------\n",
    "\n",
    "Saving and loading models across devices is relatively straightforward\n",
    "using PyTorch. In this recipe, we will experiment with saving and\n",
    "loading models across CPUs and GPUs.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Trained and Save on GPU, Load on GPU\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# \n",
    "# When loading a model on a GPU that was trained and saved on GPU, \n",
    "# simply\n",
    "# convert the initialized model to a CUDA optimized model using\n",
    "# ``model.to(torch.device('cuda'))``.\n",
    "# \n",
    "# Be sure to use the ``.to(torch.device('cuda'))`` function \n",
    "# on all model inputs \n",
    "# to prepare the data for the model.\n",
    "\n",
    "PATH = \"model.pt\"\n",
    "net.cuda()\n",
    "# Save\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# Load\n",
    "device = torch.device(\"cuda\")\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Train and Save on cpu , 同价位算力cpu:gpu = 1:14，还是别用cpu算了大哥\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# \n",
    "# When loading a model on a GPU that was trained and saved on CPU, set the\n",
    "# ``map_location`` argument in the ``torch.load()`` function to\n",
    "# ``cuda:device_id``. This loads the model to a given GPU device.\n",
    "# \n",
    "# Be sure to call ``model.to(torch.device('cuda'))`` to convert the\n",
    "# model’s parameter tensors to CUDA tensors.\n",
    "# \n",
    "# Finally, also be sure to use the ``.to(torch.device('cuda'))`` function\n",
    "# on all model inputs to prepare the data for the CUDA optimized model.\n",
    "\n",
    "net.cpu()\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# Load\n",
    "device = torch.device(\"cuda\")\n",
    "model = Net()\n",
    "# Choose whatever GPU device number you want\n",
    "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))\n",
    "# Make sure to call input = input.to(device) on any input tensors that you feed to the model\n",
    "model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cliptest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e2371522690d60d776da367a6ef0985d4bc754803ed26717289565a81c0df35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
